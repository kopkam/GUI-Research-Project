# GUI Widget Detection with YOLOv8 ğŸ¯

An AI-powered system for detecting and classifying GUI widgets (Buttons, Labels, Entry fields) in screenshots using YOLOv8 object detection.

## ğŸ‰ Status: Model Trained & Ready!

âœ“ Model trained with **96.31% mAP@50** (clean data, no text leakage)  
âœ“ Detects Buttons, Labels, and Entry fields  
âœ“ Fast inference (~23ms per image on CPU)  
âœ“ High precision (96.17%) - few false positives  
âœ“ 100 annotated training examples  

## ğŸ“‹ Project Overview

This project consists of two main components:

1. **Synthetic GUI Generator** - Creates randomized GUI layouts with annotations
2. **YOLOv8 Object Detector** - Trains and detects GUI widgets in screenshots

## ğŸš€ Quick Start

### 1. Installation

```bash
# Install dependencies
pip install -r requirements.txt
```

### 2. Try the Model

```bash
# Test on specific image
python test_model.py screenshots/screenshot_0.png

# Create visualizations
python visualize_results.py
```

### 3. Generate More Training Data (Optional)

```bash
# Open and run the notebook to generate more GUIs
jupyter notebook randomized_gui_loop.ipynb
```

### 4. Retrain (Optional)

```bash
# Prepare dataset
python prepare_yolo_dataset.py

# Train model
python train_model.py
```

## ğŸ“Š Model Performance

| Metric | Score |
|--------|-------|
| mAP@50 | 96.31% |
| mAP@50-95 | 88.28% |
| Precision | 96.17% |
| Recall | 90.68% |

See [TRAINING_RESULTS.md](TRAINING_RESULTS.md) for detailed results.

## ğŸ“ Project Structure

```
GUI-Research-Project/
â”œâ”€â”€ ğŸ“Š Data
â”‚   â”œâ”€â”€ annotations/              # JSON annotations for training data
â”‚   â”œâ”€â”€ screenshots/              # GUI screenshots
â”‚   â””â”€â”€ yolo_dataset/            # YOLO-formatted dataset
â”‚
â”œâ”€â”€ ğŸ¤– Models
â”‚   â””â”€â”€ gui_widget_detection/    # Trained model weights & results
â”‚
â”œâ”€â”€ ğŸ› ï¸ Scripts
â”‚   â”œâ”€â”€ prepare_yolo_dataset.py  # Convert annotations to YOLO format
â”‚   â”œâ”€â”€ train_model.py           # Train YOLOv8 model
â”‚   â”œâ”€â”€ test_model.py            # Evaluate model performance
â”‚   â”œâ”€â”€ visualize_results.py     # Create visualizations
â”‚   â””â”€â”€ demo.py                  # Quick demo script
â”‚
â”œâ”€â”€ ğŸ¨ GUI Generation
â”‚   â”œâ”€â”€ randomized_gui.py        # GUI generation script
â”‚   â”œâ”€â”€ randomized_gui_loop.ipynb # Batch GUI generation
â”‚   â””â”€â”€ randomized_gui.ipynb     # Interactive GUI generation
â”‚
â”œâ”€â”€ ğŸ“ Configuration
â”‚   â”œâ”€â”€ dataset.yaml             # YOLO dataset config
â”‚   â””â”€â”€ requirements.txt         # Python dependencies
â”‚
â””â”€â”€ ğŸ“– Documentation
    â”œâ”€â”€ README.md                # This file
    â”œâ”€â”€ README_MODEL.md          # Detailed model documentation
    â””â”€â”€ TRAINING_RESULTS.md      # Training results & performance
```

## ğŸ¯ Detected Widget Types

- **Button** ğŸ”´ - Interactive buttons (97.3% precision, 96.7% recall)
- **Label** ğŸŸ¢ - Text labels (93.5% precision, 75.4% recall)
- **Entry** ğŸ”µ - Input fields (97.7% precision, 100% recall)

## ğŸ“ˆ Training Details

- **Model**: YOLOv8 Nano (3M parameters)
- **Training Time**: ~34 minutes (100 epochs)
- **Dataset**: 80 train / 20 validation images
- **Augmentation**: HSV, rotation, scaling, flipping, mosaic
- **Hardware**: Trained on CPU (Apple M4)

## ğŸ”§ Advanced Options

### Retrain with Different Settings

Edit `train_model.py`:
```python
MODEL_SIZE = "yolov8s"  # Use larger model (nano/small/medium)
EPOCHS = 200            # Train longer
BATCH_SIZE = 32         # Increase batch size
```

### Generate More Training Data

Edit `randomized_gui_loop.ipynb`:
```python
for iter in tqdm(range(500)):  # Generate 500 examples
    # ... existing code ...
```


## ğŸ“š Documentation

- [README_MODEL.md](README_MODEL.md) - Comprehensive model documentation
- [TRAINING_RESULTS.md](TRAINING_RESULTS.md) - Training results and analysis
- [Ultralytics Docs](https://docs.ultralytics.com/) - YOLOv8 documentation

## ğŸ¨ Visualization

The project includes visualization tools to see model predictions:

```bash
# Create summary of predictions on multiple images
python visualize_results.py

# Visualize specific image
python visualize_results.py screenshots/screenshot_0.png
```

Results are color-coded:
- ğŸ”´ Red boxes = Buttons
- ğŸŸ¢ Green boxes = Labels
- ğŸ”µ Blue boxes = Entry fields